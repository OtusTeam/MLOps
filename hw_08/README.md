# Инференс на потоке

**Домашнее задание №8**  
**Курс MLOps**  
**Образовательная платформа «Otus»**

## Цель работы

В данном домашнем задании Вы потренируетесь в проведении инференса на потоке. Вам предстоит имитировать поступление новых данных в режиме он-лайн и передачи событий через Apache Kafka и оценки быстродействия вашей модели.

## Описание проекта

> Итак, все готово. Ваша модель работает, в облачной среде, метрики фиксируются, и вы уверены, что результаты расчета метрик имеют статистически значимое отличие. Руководство впечатлено вашими успехами и хотело бы внедрить вашу модель в работу банка.
> 
> Вместе с тем ваша модель использует данные, накопленные в озере данных за прошлые периоды и ее применение ограничено использованием офф-лайн. Вам ставят задачу адаптировать ваше решение для использования в он-лайн режиме.
> 
> Из сказанного выше вытекает необходимость получения данных в режиме реального времени. Системный администратор сообщил, что данные автоматически собираются с помощью Apache Kafka и вам могут предоставить доступ на чтение этого потока данных.
> 
> Вместе с тем не уверены, что быстродействие модели позволит ей в реальном времени обработать весь поток данных и вы понимаете, что вам возможно понадобиться разворачивать несколько экземпляров модели.

## Требования к производительности

### Нагрузка на систему

Системный администратор сообщил вам, что в среднем, поток событий составляет около **50 транзакций в секунду**, однако, перед праздниками это число может достигать **400**.

Перед внедрением вам необходимо протестировать работу модели и понять сколько экземпляров модели вам понадобиться поднять для обеспечения требуемого уровня быстродействия.

### Облачная среда

Систему MLflow желательно запустить в облачной среде, обеспечив сохранение артефактов в облачном S3 хранилище.  

## Задания

Решение будет ожидаться в виде репозитория/ветки на GitHub, с terraform конфигурациями и другим необходимым кодом для запуска всей системы.

### Обязательные задания

1. **Запустить систему Apache Kafka** в сервисе Yandex Cloud Managed Service for Apache Kafka, либо на отдельной виртуальной машине.

2. **Запустить систему Apache Airflow** в сервисе Yandex Cloud Managed Service for Apache Airflow.

3. **Создать Python скрипт**, который генерирует данные из ретроспективных файлов и записывает их в Apache Kafka.

4. **Создать Spark job**, который на потоке применяет модель к данным из Apache Kafka и записывает результаты в другой topic.

5. **Запустить систему MLflow** на отдельной виртуальной машине, а также базу данных метаданных для MLflow в сервисе Yandex Cloud Managed Service for PostgreSQL/MySQL либо на отдельной ВМ.

6. **Видоизменить DAG** для автоматизированного создания и удаления Spark-кластера, запуска скрипта и оценки качества модели и ее быстродействия.

7. **Оценить при какой интенсивности событий** (транзакций в секунду) начинает расти очередь необработанных сообщений в Apache Kafka.

### Дополнительные задания

8. **Изменить статус задач** на Kanban-доске в GitHub Projects в соответствии с достигнутыми результатами. Возможно, некоторые задачи нужно будет скорректировать, разделить на подзадачи или объединить друг с другом.

9. **Полностью удалить созданный кластер**, чтобы избежать оплаты ресурсов в период его простаивания.

## Критерии оценки

Для получения положительной оценки за работу необходимо выполнить **минимум первые семь** вышеприведенных заданий.

---

**Желаем успехов!** 