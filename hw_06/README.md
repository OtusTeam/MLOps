# Регулярное переобучение модели обнаружения мошенничества

**Домашнее задание №6**  
**Курс MLOps**  
**Образовательная платформа «Otus»**

## Цель работы

В данном домашнем задании Вы потренируетесь в использовании PySpark для обучения модели, настройку MLFlow с удаленным сервером отслеживания и хранилищем артефактов, сохранение всех артефактов, включая модель, в MLFlow с использованием Object Storage и настройку переобучения модели по расписанию с помощью Airflow на новых данных.

## Описание проекта

> Итак, данные очищены и загружены в хранилище. Вы настроили периодический запуск и процедуры очистки и подготовки на требуемой порции новых данных. Теперь можно приступать к обучению модели.
> 
> Вас продолжает беспокоить проблема поступления новых данных в систему. Антифрод-система продолжает работать и накапливать данные, а ваша система производит очистку и подготовку этих данных. Вместе с тем мошенники продолжают искать новые уязвимые места в системе защиты, а это означает, что модель, обученная единожды, скоро устареет и будет неспособна к качественному анализу транзакций...
> 
> Из сказанного выше вытекает необходимость создания системы, способной периодически переобучать модель на новых данных из озера компании. Так же вы понимаете, что новая модель не всегда может оказаться лучше старой и необходимо сравнивать метрики новой модели и использовать в системе наилучшую из всех моделей.
> 
> С помощью Apache Airflow вам нужно обеспечить периодический запуск переобучения модели на новых данных, а также контроль метрик модели и артефактов с помощью MLFlow.

## Требования к инфраструктуре

### Облачная среда

Систему MLflow желательно запустить в облачной среде, обеспечив сохранение артефактов в облачном S3 хранилище.

## Задания

Решение будет ожидаться в виде репозитория/ветки на GitHub, с terraform конфигурациями и другим необходимым кодом для запуска всей системы.

### Обязательные задания

1. **Запустить систему Apache Airflow** в сервисе Yandex Cloud Managed Service for Apache Airflow.

2. **Запустить систему MLflow** на отдельной виртуальной машине, а также базу данных метаданных для MLflow в сервисе Yandex Cloud Managed Service for PostgreSQL/MySQL либо на отдельной ВМ.

3. **Создать python скрипт** с использованием PySpark для обучения модели на облачном Spark-кластере и фиксацией результатов в MLFlow сервере.

4. **Обеспечить сохранение метрик модели и артефактов** (обученной модели) в S3 хранилище (Object storage).

5. **Разрешить периодическое исполнение** разработанного DAG в Apache AirFlow и протестировать его работоспособность.

### Дополнительные задания

6. **Изменить статус задач** на Kanban-доске в GitHub Projects в соответствии с достигнутыми результатами. Возможно, некоторые задачи нужно будет скорректировать, разделить на подзадачи или объединить друг с другом.

7. **Полностью удалить созданный кластер**, чтобы избежать оплаты ресурсов в период его простаивания.

## Критерии оценки

Для получения положительной оценки за работу необходимо выполнить **минимум первые пять** вышеприведенных заданий.

---

**Желаем успехов!** 